{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhNyQrPe7ES+D3LwuexgQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjdrms0930/bit/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5OWhwEyCctf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "& --> 백그라운드로 실행\n",
        "\n",
        "jps --> JobHistroyServer 정상실행 됐는지 확인\n",
        "\n",
        "localhost : 50070 ->\n",
        "localhost : 8088 -> All Applications\n",
        "localhost : 19888 -> jobhistory\n",
        "\n",
        "hdfs dfs -ls / => 하둡/tmp 디렉토리 생성되어 있는걸 볼 수 있음\n",
        "hdfs dfs -ls => ls:'.' : 현재 파일에서 찾을 수 없다고 나옴\n",
        "\n",
        "하둡파일은 cd명령어가 없음, 위치가 변하지 않음\n",
        "\n",
        "\n",
        "hdfs dfs -put ~/work/story.txt sample-input/ \n",
        "=> work 에 story 파일을 sample-input 으로 옮김\n",
        "\n",
        "\n",
        "하둡 정지 시키는 방법\n",
        "kill -09 (JobHistoryServer번호 (먼저 죽임)\n",
        "stop-yarn.sh (yarn 정지)\n",
        "stop-dfs.sh (dfs 정지)\n",
        "jps 해서 jps만 있으면 exit \n",
        "모든 cmd창 exit\n",
        "\n",
        "\n",
        "\n",
        "파일 보내기 : scp .\\airPerformance-0.1.jar ubuntu:~/work/java/\n",
        "start-dfs.sh\n",
        "start-yarn.sh\n",
        "jps\n",
        "mapred historyserver start&\n",
        "yarn jar ./airPerformance-0.1.jar com.adacho.driver.DepartureDelayCount air-inp\n",
        "ut dep-delay-count\n",
        "\n",
        "hdfs dfs -ls dep-delay-count\n",
        "hdfs dfs -cat dep-delay-count/part-r-00000\n",
        "\n",
        "yarn jar ./airPerformance-0.1.jar com.adacho.driver.DelayCount -D workType=departure air-input de\n",
        "p-delay-count2 출발지연\n",
        "\n",
        "yarn jar ./airPerformance-0.1.jar com.adacho.driver.DelayCount -D workType=arrival air-input arr-delay-count2\n",
        "\n",
        "리눅스 꿀팁\n",
        "\n",
        "홈디렉터리에서\n",
        "\n",
        "vi .bashrc\n",
        "\n",
        "맨아래에\n",
        "\n",
        "set -o vi 삽입\n",
        "\n",
        ":wq 저장후나와서\n",
        "\n",
        ". .bashrc 로 적용한상태에서\n",
        "\n",
        "/원하는히스토리키워드\n",
        "\n",
        "n으로 다음껄로넘길수있음\n",
        "\n",
        "수정할땐 vi모드기 때문에 i로 삽입\n",
        "\n",
        "컨트롤c로 나오면댐\n",
        "\n",
        "배열 \n",
        "\n",
        "==>> \n",
        "Linked-list  : 자료구조\n",
        "\n",
        "y = f(x) <- k\n",
        "1) 다른key, 동일한 주소x\n",
        "2) 바운더리를 지켜야함 \n",
        "3) 속도는 빨라야함\n",
        "==> hash함수\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "50yrK8OyCdWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. HiveQL\n",
        "\n",
        "● 하이브는 HiveQL 이라는 SQL문과 매우 유사한 언어를 제공\n",
        "● 대부분의 기능은 SQL과 유사하지만 다음과 같은 차이점이 있음\n",
        "a. 하이브에서 사용하는 데이터가 HDFS에 저장되는데, HDFS가 한 번 저장한 파일은 수정할 수 없기 때문에 UPDATE와 DELETE를 사용할 수 없다.\n",
        "b. 같은 이유로 INSERT도 비어 있는 데이블에 입력하거나, 이미 입력된 데이터를 overwrite 하는 경우만 가능하다. 그래서 하이브는 INSERT OVERWRITE 라는 키워드를 사용한다.\n",
        "c. SQL은 어떠한 절에서도 서브쿼리를 사용할 수 있지만 HIveQL 은 FROM 절 에서만 서브 쿼리를 사용할 수 있다.\n",
        "d. SQL의 뷰는 업데이트할 수 있고, 구체화된 뷰 또는 인라인 뷰를 지원한다. 하지만 HiveQL의 뷰는 읽기 전용이며 인라인 뷰는 지원하지 않는다.\n",
        "e. SELECT 문을 사용할 때 HAVING 절을 사용할 수 없다.\n",
        "저장 프로시저를 지원하지 않는다. 대신 맵리듀스 스크립트를 실행할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "create table airline_delay(YEAR int, MONTH int, DAY_OF_MONTH int, DAY_OF_WEEK int, FL_DATE STRING, UNIQUE_CARRIER STRING,\n",
        "TAIL_NUM STRING, FL_NUM INT, ORIGIN_AIRPORT_ID INT, ORIGIN STRING, ORIGIN_STATE_ABR STRING,\n",
        "DEST_AIRPORT_ID INT, DEST STRING, DEST_STATE_ABR STRING, CRS_DEP_TIME STRING, DEP_TIME STRING, \n",
        "DEP_DELAY INT, DEP_DELAY_NEW INT, DEP_DEL15 INT, DEP_DELAY_GROUP INT, TAXI_OUT INT, WHEELS_OFF STRING,\n",
        "WHEELS_ON STRING, TAXI_IN INT, CRS_ARR_TIME STRING, ARR_TIME STRING, ARR_DELAY INT, ARR_DELAY_NEW INT,\n",
        "ARR_DEL15 INT, ARR_DELAY_GROUP INT, CANCELLED INT, CANCELLATION_CODE STRING, DIVERTED INT, CRS_ELAPSED_TIME INT,\n",
        "ACTUAL_ELAPSED_TIME INT, AIR_TIME INT, FLIGHTS INT, DISTANCE INT, DISTANCE_GROUP INT, CARRIER_DELAY STRING,\n",
        "WEATHER_DELAY STRING, NAS_DELAY STRING, SECURITY_DELAY STRING, LATE_AIRCRAFT_DELAY STRING)\n",
        "\n",
        "\n",
        "show tables; 테이블 생성되어있나 확인\n",
        "escribe airline_delay; 테이블 속성 확인\n",
        "alter table airline_delay drop partition(delay_year=1991); => 테이블(파티션단위로) 날리는 방법\n",
        "\n",
        "select year, month, day_do_month, fl_date, unique_carrier, origin, dep_time, dep_delay\n",
        "from airline_delay\n",
        "where delay_year='1991'\n",
        "limit 20;\n",
        "=> 20개 정보 불러오기\n",
        "\n",
        "select year, month, count(*) as delay_count\n",
        "from airline_delay\n",
        "where dep_delay > 0\n",
        "group by year, month\n",
        "order by year, month;\n",
        "=> 쿼리문 이용(sort 정렬)\n",
        "\n",
        "select fl_date, unique_carrier, origin, dep_time, dep_delay\n",
        "from airline_delay a cross join (select max(dep_delay) as max_delay frrm ariline_delay where year = 20120)\n",
        "where a.dep_delay = b.max_delay;\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bxk47TnHChBJ"
      }
    }
  ]
}