{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkq2ThC3WAurRbH83UMHwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjdrms0930/bit/blob/main/20221028_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsHP72cxfeXT"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3,3), input_shape=(28, 28, 1),\n",
        "                       activation='relu'))\n",
        "model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Flatten()) # 차원과 상관없이 일차원으로 펼쳐준다.\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# 1. (1) * (3 x 3) * (32) + 32=> w = 288 / bias = 32 / total = 320 => 이미지크기 28* 28 => (28-2) * (28-2)\n",
        "# 2. (32) *  (3 x 3)* (64) + 64 =>  w =18432 / bias = 32 / total = 18496 => 이미지크기 (28-2) * (28-2) => (28-4) * (28-4)\n",
        "# 3. 이미지 크기 24 * 24였는데 (2,2) maxpooling 하면서 1/4토막 > 가로세로 절반됨\n",
        "# 4. Flatten ==> 1차원으로 눌러서 12 * 12 크기의 64개 ==> 입력 9216\n",
        "# 5. (9216) * (128) + 128 =>  w = 1179648 / bias = 128 / total = 1179776\n",
        "# 6. (128) * (10) + 10 = w = 1280 / bias = 10 / total = 1290\n",
        "# 7. Dropout 은 파라미터 영향 x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "modelpath = 'data/mnist_cnn.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1,\n",
        "                              save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "metadata": {
        "id": "OIKZHbp1-R9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = history = model.fit(X_train, y_train, validation_split=0.25, epochs=30, batch_size=200,\n",
        "                   verbose=0, callbacks=[checkpointer, early_stopping])"
      ],
      "metadata": {
        "id": "dhLjQk3lBoUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Accuracy: %.4f' % (model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "uJBRSY06Bpp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증셋과 학습셋의 오차를 저장합니다. \n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "# 그래프로 표현해 봅니다.\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
        "\n",
        "# 그래프에 그리드를 주고 레이블을 표시해 보겠습니다.\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p1dstGoDBrpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dogs vs cats"
      ],
      "metadata": {
        "id": "5BHCFM7oOEIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ],
      "metadata": {
        "id": "bgCP4AP3OGAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_dataset_dir = 'data/original/train'\n",
        "\n",
        "base_dir = 'data/cats_vs_dogs'\n",
        "if not os.path.exists(base_dir):\n",
        "    os.mkdir(base_dir)"
      ],
      "metadata": {
        "id": "0Pz2zKjUOHwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)"
      ],
      "metadata": {
        "id": "Awbzd75UOItc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)"
      ],
      "metadata": {
        "id": "7HDqwPsZOJe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)"
      ],
      "metadata": {
        "id": "jnRbzMLTOLEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = ['cat.{}.jpg'.format(i) for i in range(10000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "g8ruA69QOL5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 고양이 이미지 전체 개수:', len(os.listdir(train_cats_dir)))\n",
        "print('훈련용 강아지 이미지 전체 개수:', len(os.listdir(train_dogs_dir)))\n",
        "print('테스트용 고양이 이미지 전체 개수:', len(os.listdir(test_cats_dir)))\n",
        "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_dogs_dir)))"
      ],
      "metadata": {
        "id": "IjemBnF0OM8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3,3), input_shape=(150,150,3))) \n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())     \n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 1. (3) * (3 x 3) * (32) + 32=> w = 864 / bias = 32 / total = 896 => 이미지크기 150* 150 => 148 * 148\n",
        "# 2. 이미지 크기 74 * 74\n",
        "# 3. (32) * (3 x 3) * (64) + 64 =>  w =18432 / bias = 64 / total = 18496 => 이미지크기 74 * 74 => 72 * 72\n",
        "# 4. 이미지 크기 36 * 36\n",
        "# 5. (64) * (3 x 3) * (128) + 128 => w = 73728 / bias = 128 / total = 73856 => 이미지크기 36 * 36 => 34 * 34\n",
        "# 6. 이미지 크기 17 * 17\n",
        "# 7. (128) * (3 x 3) * (128) + 128 => w = 147456 / bias = 128 / total = 147584 => 이미지크기 17 * 17 => 15 * 15\n",
        "# 8. 이미지 크기 7 * 7\n",
        "# 9. Flatten ==> 1차원으로 눌러서 7 * 7 크기의 128개 ==> 입력 6272\n",
        "# 10. Dropout 파라미터 생성, 이미지 크기 변환 없음\n",
        "# 11. (6272) * (512) + 512 => w = 3,211,264 / bias = 512 / total = 3211776\n",
        "# 12. 512 * 1 + 1 = w = 512 / bias = 1 / total = 513\n",
        "\n",
        "# all total = 896 + 18496 + 73856 + 147584 + 3211776 + 513 = 3453121"
      ],
      "metadata": {
        "id": "PGnrLEpMRob4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "UgCA3QifRq8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4JGWhcv2XKtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150),\n",
        "                                                   batch_size=20, class_mode='binary')"
      ],
      "metadata": {
        "id": "A4_EVZjEXLGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('배치 데이터 크기:', data_batch.shape )\n",
        "    print('배치 레이블 크기:', labels_batch.shape )\n",
        "    break"
      ],
      "metadata": {
        "id": "4tHSzVoNXNQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=30, validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "qPaHppdCa6b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T0LU5Ns0eWMn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}